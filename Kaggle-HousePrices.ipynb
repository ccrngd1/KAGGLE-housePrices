{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy --upgrade\n",
    "!pip3 install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries                                   \n",
    "import os     \n",
    "\n",
    "# data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn utilities\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# prediction\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"50\"}\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "bucket = 'lawsnic-east1'\n",
    "prefix = 'kaggle/house-prices-advanced-regression-techniques' \n",
    "output_path = 's3://{}/{}/{}/output'.format(bucket, prefix, 'abalone-xgb-built-in-algo')\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", \"us-east-2\", \"1.5-1\")\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=output_path)\n",
    "\n",
    "train_data = pd.read_csv(\"./train.csv\")\n",
    "test_data = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "pd.options.display.max_columns = train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['Id','PoolQC', 'MiscFeature', '2ndFlrSF','FireplaceQu','YearBuilt','GarageCars'])\n",
    "test_data = test_data.drop(columns=['Id','PoolQC', 'MiscFeature', '2ndFlrSF','FireplaceQu','YearBuilt','GarageCars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['MSSubClass'] = ((train_data['MSSubClass'].astype(int)/10)+65).apply(int).apply(chr)\n",
    "test_data['MSSubClass'] = ((test_data['MSSubClass'].astype(int)/10)+65).apply(int).apply(chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_num = train_data.select_dtypes(exclude=['object'])\n",
    "test_data_num = test_data.select_dtypes(exclude=['object'])\n",
    "train_data_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cat = train_data.select_dtypes(include=['object'])\n",
    "test_data_cat = test_data.select_dtypes(include=['object'])\n",
    "train_data_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_num.hist(figsize=(25, 30), bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, len(train_data_cat.columns))\n",
    "fig, ax = plt.subplots(45,figsize=(30,100))\n",
    "for i, categorical_feature in enumerate(train_data_cat):\n",
    "    train_data_cat[categorical_feature].value_counts().plot(kind=\"bar\", ax=ax[i]).set_title(categorical_feature)\n",
    "    #train_data_cat[categorical_feature].value_counts().plot(subplots=True, kind=\"bar\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "selector.fit(train_data_num.iloc[:, :-1])\n",
    "\n",
    "sup = selector.get_support()\n",
    "\n",
    "print('Number of retained features: ', sum(sup))\n",
    "\n",
    "print('Number low-variance features: ', sum(~sup))\n",
    "\n",
    "low_var_fet = train_data_num.drop(['SalePrice'], axis=1).loc[:, ~sup].columns.values\n",
    "\n",
    "print('Low-variance features: ', low_var_fet)\n",
    "\n",
    "print('Before: ',train_data_num.shape, test_data_num.shape)\n",
    "train_data_num.drop(low_var_fet, axis=1, inplace=True)\n",
    "test_data_num.drop(low_var_fet, axis=1, inplace=True)\n",
    "print('After: ', train_data_num.shape, test_data_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "corr_mat = train_data_num.corr('pearson')\n",
    "\n",
    "# replace very weak correlation\n",
    "corr_mat[(corr_mat < 0.3) & (corr_mat > -0.3)] = 0\n",
    "\n",
    "# define triangular mask for better visibility\n",
    "mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(corr_mat, mask=mask, vmax=1.0, vmin=-1.0, square=True, annot=True, annot_kws={\"size\": 9, \"color\": \"black\"}, linewidths=0.1, cmap='rocket');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = corr_mat['SalePrice'].drop(['SalePrice'])\n",
    "corr_features.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_feats = corr_features[(abs(corr_features) >= 0.3)].index.tolist()\n",
    "#chosen_feats\n",
    "cleaned_train_data = train_data[['SalePrice'] + chosen_feats]\n",
    "cleaned_test_data = test_data[chosen_feats]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitData_train, splitData_val, splitData_test = np.split(cleaned_train_data.sample(frac=1, random_state=1729), [int(0.7 * len(cleaned_train_data)), int(0.9 * len(cleaned_train_data))])   # Randomly sort the data then split out first 70%, second 20%, and last 10%\n",
    "\n",
    "splitData_train.to_csv('train/train.csv', index=False, header=False)\n",
    "splitData_val.to_csv('validation/validation.csv', index=False, header=False)\n",
    " \n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'input/train/train.csv')).upload_file('train/train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'input/validation/validation.csv')).upload_file('validation/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    sagemaker.image_uris.retrieve(\"xgboost\", sess.boto_region_name, \"1.5-1\"),\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    verbosity=0,\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = TrainingInput(    s3_data=\"s3://{}/{}/input/train/\".format(bucket, prefix), content_type=\"csv\")\n",
    "s3_input_validation = TrainingInput(    s3_data=\"s3://{}/{}/input/validation/\".format(bucket, prefix), content_type=\"csv\")\n",
    "\n",
    "xgb.fit({\"train\": s3_input_train, \"validation\": s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(prefix, 'train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
